{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://chriskhanhtran.github.io/posts/cnn-sentence-classification/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "Device name: NVIDIA GeForce GTX 1070\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():       \n",
    "    device = torch.device(\"cuda\")\n",
    "    print(f'There are {torch.cuda.device_count()} GPU(s) available.')\n",
    "    print('Device name:', torch.cuda.get_device_name(0))\n",
    "\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def record_data_info(class_nm, txt_cnt):\n",
    "    with open('../data/info.txt', 'a') as f:\n",
    "        f.write(class_nm + ': ' + str(txt_cnt) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def record_nonAscii_txt(fn):\n",
    "    with open('../data/nonAsciiTxt.txt', 'a') as f:\n",
    "        f.write(fn + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_nonAscii_info(nonAsciiDict):\n",
    "    with open('../data/nonAsciiInfo.txt', 'a') as f:\n",
    "        for key in nonAsciiDict:\n",
    "            f.write(key + '\\t : ' + str(nonAsciiDict[key]) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df():\n",
    "    data_path = '../data/code25/'\n",
    "    class_dir_list = [os.listdir(data_path)]\n",
    "\n",
    "    # count = 0\n",
    "    \n",
    "    data_list = []\n",
    "    class_list = []\n",
    "\n",
    "    max_bytes, min_bytes = -1, 999999\n",
    "    size_dict = {}\n",
    "\n",
    "    for class_nm in os.listdir(data_path):\n",
    "        \n",
    "        class_txt_cnt = 0\n",
    "        class_flag = 0\n",
    "\n",
    "        if class_nm == '.DS_Store': continue\n",
    "\n",
    "        while class_flag != 1:\n",
    "            for txt_file in os.listdir(data_path + class_nm):\n",
    "                \n",
    "                if txt_file.endswith('.txt'):\n",
    "                    file_path = data_path + class_nm + '/' + txt_file\n",
    "\n",
    "                    # file_size = os.path.getsize(file_path)\n",
    "\n",
    "                    # if not file_size in size_dict:\n",
    "                    #     size_dict[file_size] = 1\n",
    "                    # else:\n",
    "                    #     size_dict[file_size] += 1\n",
    "\n",
    "                    # if file_size > max_bytes: max_bytes = file_size\n",
    "                    # if file_size < min_bytes: min_bytes = file_size\n",
    "                \n",
    "                    nonAsciiFile = {}\n",
    "\n",
    "                    with open(file_path, 'r') as file:\n",
    "                        class_label = class_nm\n",
    "\n",
    "                        strings = file.readlines()\n",
    "                        data = ' '.join(strings)\n",
    "\n",
    "                        char_cnt = 0\n",
    "                        data_124 = ''\n",
    "\n",
    "                        for chars in data:\n",
    "                            \n",
    "                            if not chars.isascii():\n",
    "\n",
    "                                if file_path not in nonAsciiFile:\n",
    "                                    nonAsciiFile[file_path] = 1\n",
    "                                else:\n",
    "                                    nonAsciiFile[file_path] += 1\n",
    "                                \n",
    "                                record_nonAscii_txt(file_path + '\\t : ' + chars)\n",
    "                            \n",
    "                            if chars.isascii():\n",
    "                                \n",
    "                                if char_cnt != 124:\n",
    "                                    char_cnt += 1\n",
    "                                    data_124 += chars\n",
    "                                elif char_cnt == 124:\n",
    "                                    char_cnt = 0\n",
    "                                    class_txt_cnt += 1\n",
    "                                    data_list.append(data_124)\n",
    "                                    class_list.append(class_label)\n",
    "\n",
    "                                    if not len(data_124) in size_dict:\n",
    "                                        size_dict[len(data_124)] = 1\n",
    "                                    else:\n",
    "                                        size_dict[len(data_124)] += 1\n",
    "                                    \n",
    "                                    data_124 = ''\n",
    "\n",
    "                                if class_txt_cnt == 10000:\n",
    "                                    class_flag = 1\n",
    "                                    break\n",
    "                    \n",
    "                    print_nonAscii_info(nonAsciiFile)\n",
    "                \n",
    "                if class_flag == 1:\n",
    "                    break\n",
    "\n",
    "                    # count += 1\n",
    "                \n",
    "                # if count == 10: break\n",
    "                \n",
    "\n",
    "        record_data_info(class_nm, class_txt_cnt)\n",
    "        # break\n",
    "    \n",
    "    data = {'sourceCode': data_list, 'classLabel': class_list}\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    return df, [max_bytes, min_bytes], size_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df, size_info, size_dict = get_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max bytes:  -1\n",
      "max KB: -0.0009765625\n",
      "\n",
      "min bytes:  999999\n",
      "min KB: 976.5615234375\n"
     ]
    }
   ],
   "source": [
    "print('max bytes: ', size_info[0])\n",
    "print('max KB:', size_info[0]/1024)\n",
    "\n",
    "print()\n",
    "\n",
    "print('min bytes: ', size_info[1])\n",
    "print('min KB:', size_info[1]/1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from turtle import position\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sizes = list(size_dict.keys())\n",
    "counts = list(size_dict.values())\n",
    "\n",
    "fig = plt.figure(figsize = (10, 5))\n",
    "\n",
    "plt.bar(sizes, counts)\n",
    "\n",
    "plt.xlabel('sizes in Bytes')\n",
    "plt.ylabel('# count of size')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sourceCode_np = df.sourceCode.values\n",
    "codeClass_np = df.classLabel.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from collections import defaultdict\n",
    "\n",
    "def split(str):\n",
    "    return [char for char in str]\n",
    "\n",
    "def tokenize(sourceCode):\n",
    "    \"\"\"Tokenize texts, build vocabulary and find maximum sentence length.\n",
    "    \n",
    "    Args:\n",
    "        texts (List[str]): List of text data\n",
    "    \n",
    "    Returns:\n",
    "        tokenized_texts (List[List[str]]): List of list of tokens\n",
    "        word2idx (Dict): Vocabulary built from the corpus\n",
    "        max_len (int): Maximum sentence length\n",
    "    \"\"\"\n",
    "\n",
    "    max_len = 0\n",
    "    tokenized_codes = []\n",
    "    ch2idx = {}\n",
    "\n",
    "    # Add <pad> and <unk> tokens to the vocabulary\n",
    "    ch2idx['<pad>'] = 0\n",
    "\n",
    "    # Building our vocab from the corpus starting from index 2\n",
    "    idx = 1\n",
    "    for code in sourceCode:\n",
    "        tokenized_code = split(code)\n",
    "\n",
    "        # Add `tokenized_sent` to `tokenized_texts`\n",
    "        tokenized_codes.append(tokenized_code)\n",
    "\n",
    "        # Add new token to `word2idx`\n",
    "        for token in tokenized_code:\n",
    "            if token not in ch2idx:\n",
    "                ch2idx[token] = idx\n",
    "                idx += 1\n",
    "\n",
    "        # Update `max_len`\n",
    "        max_len = max(max_len, len(tokenized_code))\n",
    "\n",
    "    return tokenized_codes, ch2idx, max_len\n",
    "\n",
    "def encode(tokenized_codes, ch2idx, max_len):\n",
    "    \"\"\"Pad each sentence to the maximum sentence length and encode tokens to\n",
    "    their index in the vocabulary.\n",
    "\n",
    "    Returns:\n",
    "        input_ids (np.array): Array of token indexes in the vocabulary with\n",
    "            shape (N, max_len). It will the input of our CNN model.\n",
    "    \"\"\"\n",
    "\n",
    "    input_ids = []\n",
    "    for tokenized_code in tokenized_codes:\n",
    "        # Pad sentences to max_len\n",
    "        tokenized_code += ['<pad>'] * (max_len - len(tokenized_code))\n",
    "\n",
    "        # Encode tokens to input_ids\n",
    "        input_id = [ch2idx.get(token) for token in tokenized_code]\n",
    "        input_ids.append(input_id)\n",
    "    \n",
    "    return np.array(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Tokenize, build vocabulary, encode tokens\n",
    "print(\"Tokenizing...\\n\")\n",
    "tokenized_sourceCodes, ch2idx, max_len = tokenize(sourceCode_np)\n",
    "input_ids = encode(tokenized_sourceCodes, ch2idx, max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_ch2idx(ch2idx):\n",
    "    with open('../data/ch2idx.txt', 'a') as f:\n",
    "        for key in ch2idx:\n",
    "            f.write(key + '\\t : ' + str(ch2idx[key]) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_ch2idx(ch2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_encode_class(classes):\n",
    "    encoded_class = []\n",
    "    class2idx = {}\n",
    "    idx = 0\n",
    "\n",
    "    for one_class in classes:\n",
    "\n",
    "        if not one_class in class2idx:\n",
    "            class2idx[one_class] = idx\n",
    "            idx += 1\n",
    "        \n",
    "        encoded_class.append(class2idx[one_class])\n",
    "\n",
    "    return np.array(encoded_class), class2idx, len(class2idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_class2idx, class2idx, num_classes = tokenize_encode_class(codeClass_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_inputs, val_inputs, train_labels, val_labels = train_test_split(\n",
    "    input_ids, encoded_class2idx, test_size = 0.2, random_state = 43\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import (TensorDataset, DataLoader, RandomSampler,\n",
    "                              SequentialSampler)\n",
    "\n",
    "def data_loader(train_inputs, val_inputs, train_labels, val_labels,\n",
    "                batch_size=50):\n",
    "    \"\"\"Convert train and validation sets to torch.Tensors and load them to\n",
    "    DataLoader.\n",
    "    \"\"\"\n",
    "\n",
    "    # Convert data type to torch.Tensor\n",
    "    train_inputs, val_inputs, train_labels, val_labels =\\\n",
    "    tuple(torch.tensor(data) for data in\n",
    "          [train_inputs, val_inputs, train_labels, val_labels])\n",
    "\n",
    "    # Specify batch_size\n",
    "    batch_size = 50\n",
    "\n",
    "    # Create DataLoader for training data\n",
    "    train_data = TensorDataset(train_inputs, train_labels)\n",
    "    train_sampler = RandomSampler(train_data)\n",
    "    train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size, drop_last=True)\n",
    "\n",
    "    # Create DataLoader for validation data\n",
    "    val_data = TensorDataset(val_inputs, val_labels)\n",
    "    val_sampler = SequentialSampler(val_data)\n",
    "    val_dataloader = DataLoader(val_data, sampler=val_sampler, batch_size=batch_size, drop_last=True)\n",
    "\n",
    "    return train_dataloader, val_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data to PyTorch DataLoader\n",
    "train_dataloader, val_dataloader = \\\n",
    "data_loader(train_inputs, val_inputs, train_labels, val_labels, batch_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class CNN_NLP(nn.Module):\n",
    "    \"\"\"An 1D Convulational Neural Network for Sentence Classification.\"\"\"\n",
    "    def __init__(self,\n",
    "                 pretrained_embedding=None,\n",
    "                 freeze_embedding=False,\n",
    "                 vocab_size=None,\n",
    "                 embed_dim=300,\n",
    "                 filter_sizes=[16, 32, 16],\n",
    "                 num_filters=[100, 100, 100],\n",
    "                 num_classes=2,\n",
    "                 dropout=0.5):\n",
    "        \"\"\"\n",
    "        The constructor for CNN_NLP class.\n",
    "\n",
    "        Args:\n",
    "            pretrained_embedding (torch.Tensor): Pretrained embeddings with\n",
    "                shape (vocab_size, embed_dim)\n",
    "            freeze_embedding (bool): Set to False to fine-tune pretraiend\n",
    "                vectors. Default: False\n",
    "            vocab_size (int): Need to be specified when not pretrained word\n",
    "                embeddings are not used.\n",
    "            embed_dim (int): Dimension of word vectors. Need to be specified\n",
    "                when pretrained word embeddings are not used. Default: 300\n",
    "            filter_sizes (List[int]): List of filter sizes. Default: [3, 4, 5]\n",
    "            num_filters (List[int]): List of number of filters, has the same\n",
    "                length as `filter_sizes`. Default: [100, 100, 100]\n",
    "            n_classes (int): Number of classes. Default: 2\n",
    "            dropout (float): Dropout rate. Default: 0.5\n",
    "        \"\"\"\n",
    "\n",
    "        super(CNN_NLP, self).__init__()\n",
    "        # Embedding layer\n",
    "        if pretrained_embedding is not None:\n",
    "            self.vocab_size, self.embed_dim = pretrained_embedding.shape\n",
    "            self.embedding = nn.Embedding.from_pretrained(pretrained_embedding,\n",
    "                                                          freeze=freeze_embedding)\n",
    "        else:\n",
    "            self.embed_dim = embed_dim\n",
    "            self.embedding = nn.Embedding(num_embeddings=vocab_size,\n",
    "                                          embedding_dim=self.embed_dim,\n",
    "                                          padding_idx=0,\n",
    "                                          max_norm=5.0)\n",
    "        # Conv Network\n",
    "        self.conv1d_list = nn.ModuleList([\n",
    "            nn.Conv1d(in_channels=self.embed_dim,\n",
    "                      out_channels=num_filters[i],\n",
    "                      kernel_size=filter_sizes[i])\n",
    "            for i in range(len(filter_sizes))\n",
    "        ])\n",
    "        # Fully-connected layer and Dropout\n",
    "        self.fc = nn.Linear(np.sum(num_filters), num_classes)\n",
    "        self.activation = nn.LogSoftmax(dim=-1)\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "    def forward(self, input_ids):\n",
    "        \"\"\"Perform a forward pass through the network.\n",
    "\n",
    "        Args:\n",
    "            input_ids (torch.Tensor): A tensor of token ids with shape\n",
    "                (batch_size, max_sent_length)\n",
    "\n",
    "        Returns:\n",
    "            logits (torch.Tensor): Output logits with shape (batch_size,\n",
    "                n_classes)\n",
    "        \"\"\"\n",
    "\n",
    "        # Get embeddings from `input_ids`. Output shape: (b, max_len, embed_dim)\n",
    "        x_embed = self.embedding(input_ids).float()\n",
    "\n",
    "        # Permute `x_embed` to match input shape requirement of `nn.Conv1d`.\n",
    "        # Output shape: (b, embed_dim, max_len)\n",
    "        x_reshaped = x_embed.permute(0, 2, 1)\n",
    "\n",
    "        # Apply CNN and ReLU. Output shape: (b, num_filters[i], L_out)\n",
    "        x_conv_list = [F.relu(conv1d(x_reshaped)) for conv1d in self.conv1d_list]\n",
    "\n",
    "        # Max pooling. Output shape: (b, num_filters[i], 1)\n",
    "        x_pool_list = [F.max_pool1d(x_conv, kernel_size=x_conv.shape[2])\n",
    "            for x_conv in x_conv_list]\n",
    "        \n",
    "        # Concatenate x_pool_list to feed the fully connected layer.\n",
    "        # Output shape: (b, sum(num_filters))\n",
    "        x_fc = torch.cat([x_pool.squeeze(dim=2) for x_pool in x_pool_list],\n",
    "                         dim=1)\n",
    "        \n",
    "        # Compute logits. Output shape: (b, n_classes)\n",
    "        logits = self.activation(self.fc(self.dropout(x_fc)))\n",
    "\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "def initilize_model(pretrained_embedding=None,\n",
    "                    freeze_embedding=False,\n",
    "                    vocab_size=None,\n",
    "                    embed_dim=20,\n",
    "                    filter_sizes=[16, 32, 16],\n",
    "                    num_filters=[100, 100, 100],\n",
    "                    num_classes=2,\n",
    "                    dropout=0.5,\n",
    "                    learning_rate=0.01):\n",
    "    \"\"\"Instantiate a CNN model and an optimizer.\"\"\"\n",
    "\n",
    "    assert (len(filter_sizes) == len(num_filters)), \"filter_sizes and \\\n",
    "    num_filters need to be of the same length.\"\n",
    "\n",
    "    # Instantiate CNN model\n",
    "    cnn_model = CNN_NLP(pretrained_embedding=pretrained_embedding,\n",
    "                        freeze_embedding=freeze_embedding,\n",
    "                        vocab_size=vocab_size,\n",
    "                        embed_dim=embed_dim,\n",
    "                        filter_sizes=filter_sizes,\n",
    "                        num_filters=num_filters,\n",
    "                        num_classes=num_classes,\n",
    "                        dropout=0.5)\n",
    "    \n",
    "    # Send model to `device` (GPU/CPU)\n",
    "    cnn_model.to(device)\n",
    "\n",
    "    # Instantiate Adadelta optimizer\n",
    "    optimizer = optim.Adadelta(cnn_model.parameters(),\n",
    "                               lr=learning_rate,\n",
    "                               rho=0.95)\n",
    "\n",
    "    return cnn_model, optimizer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch TensorBoard support\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from datetime import datetime\n",
    "\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "writer = SummaryWriter('runs/sourceCodeCNN{}'.format(timestamp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import time\n",
    "\n",
    "# Specify loss function\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "def set_seed(seed_value=42):\n",
    "    \"\"\"Set seed for reproducibility.\"\"\"\n",
    "\n",
    "    random.seed(seed_value)\n",
    "    np.random.seed(seed_value)\n",
    "    torch.manual_seed(seed_value)\n",
    "    torch.cuda.manual_seed_all(seed_value)\n",
    "\n",
    "def train(model, optimizer, train_dataloader, title, val_dataloader=None, epochs=10):\n",
    "    \"\"\"Train the CNN model.\"\"\"\n",
    "    \n",
    "    # Tracking best validation accuracy\n",
    "    best_accuracy = 0\n",
    "\n",
    "    # Start training loop\n",
    "    print(\"Start training...\\n\")\n",
    "    print(f\"{'Epoch':^7} | {'Train Loss':^12} | {'Val Loss':^10} | {'Val Acc':^9} | {'Elapsed':^9}\")\n",
    "    print(\"-\"*60)\n",
    "\n",
    "    for epoch_i in range(epochs):\n",
    "        # =======================================\n",
    "        #               Training\n",
    "        # =======================================\n",
    "\n",
    "        # Tracking time and loss\n",
    "        t0_epoch = time.time()\n",
    "        tot_train_loss = []\n",
    "\n",
    "        # Put the model into the training mode\n",
    "        model.train()\n",
    "        train_accuracy = []\n",
    "        for step, batch in enumerate(train_dataloader):\n",
    "             # Load batch to GPU\n",
    "            b_input_ids, b_labels = tuple(t.to(device) for t in batch)\n",
    "\n",
    "            # Zero out any previously calculated gradients\n",
    "            model.zero_grad()\n",
    "\n",
    "            # Perform a forward pass. This will return logits.\n",
    "            logits = model(b_input_ids)\n",
    "\n",
    "            # Compute loss and accumulate the loss values\n",
    "            loss = loss_fn(logits, b_labels)\n",
    "            tot_train_loss.append(loss.item())\n",
    "\n",
    "            # Get the predictions\n",
    "            preds = torch.argmax(logits, dim=1).flatten()\n",
    "\n",
    "            # Calculate the accuracy rate\n",
    "            accuracy = (preds == b_labels).cpu().numpy().mean() * 100\n",
    "            train_accuracy.append(accuracy)\n",
    "\n",
    "            # Perform a backward pass to calculate gradients\n",
    "            loss.backward()\n",
    "\n",
    "            # Update parameters\n",
    "            optimizer.step()\n",
    "\n",
    "        # Calculate the average loss over the entire training data\n",
    "        avg_train_loss = np.mean(tot_train_loss)\n",
    "        train_accuracy = np.mean(train_accuracy)\n",
    "\n",
    "        # =======================================\n",
    "        #               Evaluation\n",
    "        # =======================================\n",
    "        if val_dataloader is not None:\n",
    "            # After the completion of each training epoch, measure the model's\n",
    "            # performance on our validation set.\n",
    "            val_loss, val_accuracy = evaluate(model, val_dataloader)\n",
    "\n",
    "            # Track the best accuracy\n",
    "            if val_accuracy > best_accuracy:\n",
    "                best_accuracy = val_accuracy\n",
    "\n",
    "            # Print performance over the entire training data\n",
    "            time_elapsed = time.time() - t0_epoch\n",
    "            print(f\"{epoch_i + 1:^7} | {avg_train_loss:^12.6f} | {val_loss:^10.6f} | {val_accuracy:^9.2f} | {time_elapsed:^9.2f}\")\n",
    "\n",
    "        writer.add_scalars(title + '-CNN Training vs. Testing Loss',\n",
    "                { 'Train' : avg_train_loss, 'Test' : val_loss },\n",
    "                epoch_i + 1)\n",
    "\n",
    "        writer.add_scalars(title + '-CNN Training vs. Testing Accuracy',\n",
    "                    { 'Train' : train_accuracy, 'Test' : val_accuracy },\n",
    "                    epoch_i + 1)\n",
    "            \n",
    "    print(\"\\n\")\n",
    "    print(f\"Training complete! Best accuracy: {best_accuracy:.2f}%.\")\n",
    "\n",
    "def evaluate(model, val_dataloader):\n",
    "    \"\"\"After the completion of each training epoch, measure the model's\n",
    "    performance on our validation set.\n",
    "    \"\"\"\n",
    "    # Put the model into the evaluation mode. The dropout layers are disabled\n",
    "    # during the test time.\n",
    "    model.eval()\n",
    "\n",
    "    # Tracking variables\n",
    "    val_accuracy = []\n",
    "    val_loss = []\n",
    "\n",
    "    # For each batch in our validation set...\n",
    "    for batch in val_dataloader:\n",
    "        # Load batch to GPU\n",
    "        b_input_ids, b_labels = tuple(t.to(device) for t in batch)\n",
    "\n",
    "        # Compute logits\n",
    "        with torch.no_grad():\n",
    "            logits = model(b_input_ids)\n",
    "\n",
    "        # Compute loss\n",
    "        loss = loss_fn(logits, b_labels)\n",
    "        val_loss.append(loss.item())\n",
    "\n",
    "        # Get the predictions\n",
    "        preds = torch.argmax(logits, dim=1).flatten()\n",
    "\n",
    "        # Calculate the accuracy rate\n",
    "        accuracy = (preds == b_labels).cpu().numpy().mean() * 100\n",
    "        val_accuracy.append(accuracy)\n",
    "\n",
    "    # Compute the average accuracy and loss over the validation set.\n",
    "    val_loss = np.mean(val_loss)\n",
    "    val_accuracy = np.mean(val_accuracy)\n",
    "\n",
    "    return val_loss, val_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training...\n",
      "\n",
      " Epoch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (50) must match the size of tensor b (21) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/arise/auto_debug_capstone/source_code_classification/src/cnn.ipynb Cell 25\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/arise/auto_debug_capstone/source_code_classification/src/cnn.ipynb#ch0000022?line=1'>2</a>\u001b[0m set_seed(\u001b[39m42\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/arise/auto_debug_capstone/source_code_classification/src/cnn.ipynb#ch0000022?line=2'>3</a>\u001b[0m cnn_rand, optimizer \u001b[39m=\u001b[39m initilize_model(vocab_size\u001b[39m=\u001b[39m\u001b[39mlen\u001b[39m(ch2idx),\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/arise/auto_debug_capstone/source_code_classification/src/cnn.ipynb#ch0000022?line=3'>4</a>\u001b[0m                                       embed_dim\u001b[39m=\u001b[39m\u001b[39m100\u001b[39m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/arise/auto_debug_capstone/source_code_classification/src/cnn.ipynb#ch0000022?line=4'>5</a>\u001b[0m                                       filter_sizes\u001b[39m=\u001b[39m[\u001b[39m8\u001b[39m, \u001b[39m16\u001b[39m, \u001b[39m32\u001b[39m, \u001b[39m64\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/arise/auto_debug_capstone/source_code_classification/src/cnn.ipynb#ch0000022?line=7'>8</a>\u001b[0m                                       num_classes\u001b[39m=\u001b[39m\u001b[39mlen\u001b[39m(class2idx),\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/arise/auto_debug_capstone/source_code_classification/src/cnn.ipynb#ch0000022?line=8'>9</a>\u001b[0m                                       dropout\u001b[39m=\u001b[39m\u001b[39m0.5\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/arise/auto_debug_capstone/source_code_classification/src/cnn.ipynb#ch0000022?line=9'>10</a>\u001b[0m train(cnn_rand, optimizer, train_dataloader, \u001b[39m'\u001b[39;49m\u001b[39m4LayerChngedKernel+soft+multLoss\u001b[39;49m\u001b[39m'\u001b[39;49m, val_dataloader, epochs\u001b[39m=\u001b[39;49m\u001b[39m20\u001b[39;49m)\n",
      "\u001b[1;32m/home/arise/auto_debug_capstone/source_code_classification/src/cnn.ipynb Cell 25\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, optimizer, train_dataloader, title, val_dataloader, epochs)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/arise/auto_debug_capstone/source_code_classification/src/cnn.ipynb#ch0000022?line=45'>46</a>\u001b[0m logits \u001b[39m=\u001b[39m model(b_input_ids)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/arise/auto_debug_capstone/source_code_classification/src/cnn.ipynb#ch0000022?line=47'>48</a>\u001b[0m \u001b[39m# Compute loss and accumulate the loss values\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/arise/auto_debug_capstone/source_code_classification/src/cnn.ipynb#ch0000022?line=48'>49</a>\u001b[0m loss \u001b[39m=\u001b[39m loss_fn(logits, b_labels)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/arise/auto_debug_capstone/source_code_classification/src/cnn.ipynb#ch0000022?line=49'>50</a>\u001b[0m tot_train_loss\u001b[39m.\u001b[39mappend(loss\u001b[39m.\u001b[39mitem())\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/arise/auto_debug_capstone/source_code_classification/src/cnn.ipynb#ch0000022?line=51'>52</a>\u001b[0m \u001b[39m# Get the predictions\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/modules/loss.py:1213\u001b[0m, in \u001b[0;36mMultiLabelSoftMarginLoss.forward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m   1212\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor, target: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m-> 1213\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mmultilabel_soft_margin_loss(\u001b[39minput\u001b[39;49m, target, weight\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, reduction\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mreduction)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/functional.py:3428\u001b[0m, in \u001b[0;36mmultilabel_soft_margin_loss\u001b[0;34m(input, target, weight, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   3425\u001b[0m \u001b[39mif\u001b[39;00m size_average \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m reduce \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   3426\u001b[0m     reduction \u001b[39m=\u001b[39m _Reduction\u001b[39m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[0;32m-> 3428\u001b[0m loss \u001b[39m=\u001b[39m \u001b[39m-\u001b[39m(target \u001b[39m*\u001b[39;49m logsigmoid(\u001b[39minput\u001b[39;49m) \u001b[39m+\u001b[39m (\u001b[39m1\u001b[39m \u001b[39m-\u001b[39m target) \u001b[39m*\u001b[39m logsigmoid(\u001b[39m-\u001b[39m\u001b[39minput\u001b[39m))\n\u001b[1;32m   3430\u001b[0m \u001b[39mif\u001b[39;00m weight \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   3431\u001b[0m     loss \u001b[39m=\u001b[39m loss \u001b[39m*\u001b[39m weight\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (50) must match the size of tensor b (21) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "# CNN-rand: Word vectors are randomly initialized.\n",
    "set_seed(42)\n",
    "cnn_rand, optimizer = initilize_model(vocab_size=len(ch2idx),\n",
    "                                      embed_dim=100,\n",
    "                                      filter_sizes=[8, 16, 32, 64],\n",
    "                                      num_filters=[100, 200, 200, 100],\n",
    "                                      learning_rate=0.25,\n",
    "                                      num_classes=len(class2idx),\n",
    "                                      dropout=0.5)\n",
    "train(cnn_rand, optimizer, train_dataloader, '4LayerChngedKernel+soft+multLoss', val_dataloader, epochs=20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "348b9cd948ce87438be2e622031b2ecfa29bc2d3ecc0fd03127b9a24b30227df"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
