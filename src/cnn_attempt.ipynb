{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "import data\n",
    "import utils\n",
    "import info_recorder as ir\n",
    "import data_loader as dl\n",
    "import initializer as init\n",
    "import trainer as tn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://chriskhanhtran.github.io/posts/cnn-sentence-classification/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "Device name: NVIDIA GeForce GTX 1070\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():       \n",
    "    device = torch.device(\"cuda\")\n",
    "    print(f'There are {torch.cuda.device_count()} GPU(s) available.')\n",
    "    print('Device name:', torch.cuda.get_device_name(0))\n",
    "\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df, size_info, size_dict = data.get_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sourceCode_np = df.sourceCode.values\n",
    "codeClass_np = df.classLabel.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Tokenize, build vocabulary, encode tokens\n",
    "print(\"Tokenizing...\\n\")\n",
    "tokenized_sourceCodes, ch2idx, max_len = utils.tokenize(sourceCode_np)\n",
    "input_ids = utils.encode(tokenized_sourceCodes, ch2idx, max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ir.record_ch2idx(ch2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_class2idx, class2idx, num_classes = utils.tokenize_encode_class(codeClass_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_inputs, val_inputs, train_labels, val_labels = train_test_split(\n",
    "    input_ids, encoded_class2idx, test_size = 0.2, random_state = 43\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data to PyTorch DataLoader\n",
    "train_dataloader, val_dataloader = dl.data_loader(train_inputs, val_inputs, train_labels, val_labels, batch_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch TensorBoard support\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from datetime import datetime\n",
    "\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "writer = SummaryWriter('stableKZ/cnn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training...\n",
      "\n",
      " Epoch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
      "------------------------------------------------------------\n",
      "   1    |   1.618258   |  1.038399  |   71.15   |   42.27  \n",
      "   2    |   1.011508   |  0.822850  |   76.84   |   41.56  \n",
      "   3    |   0.857686   |  0.747237  |   79.16   |   41.63  \n",
      "   4    |   0.776052   |  0.694726  |   80.57   |   41.71  \n",
      "   5    |   0.715773   |  0.665403  |   81.11   |   41.47  \n",
      "   6    |   0.675068   |  0.652499  |   81.62   |   41.38  \n",
      "   7    |   0.639666   |  0.635737  |   82.29   |   41.57  \n",
      "   8    |   0.610466   |  0.622353  |   82.50   |   41.87  \n",
      "   9    |   0.590977   |  0.619485  |   82.81   |   41.82  \n",
      "  10    |   0.570781   |  0.613228  |   83.11   |   41.48  \n",
      "  11    |   0.551683   |  0.607242  |   83.14   |   41.68  \n",
      "  12    |   0.537102   |  0.601666  |   83.36   |   41.59  \n",
      "  13    |   0.523023   |  0.602169  |   83.30   |   42.30  \n",
      "  14    |   0.515597   |  0.600037  |   83.39   |   41.97  \n",
      "  15    |   0.501656   |  0.593653  |   83.82   |   41.72  \n",
      "  16    |   0.490288   |  0.599067  |   83.54   |   41.80  \n",
      "  17    |   0.484625   |  0.598121  |   83.67   |   42.26  \n",
      "  18    |   0.475953   |  0.586552  |   83.97   |   42.05  \n",
      "  19    |   0.468776   |  0.599748  |   84.05   |   40.28  \n",
      "  20    |   0.461247   |  0.588527  |   84.04   |   40.40  \n",
      "\n",
      "\n",
      "Training complete! Best accuracy: 84.05%.\n"
     ]
    }
   ],
   "source": [
    "# CNN-rand: Word vectors are randomly initialized.\n",
    "tn.set_seed(42)\n",
    "cnn_rand, optimizer = init.initilize_model(device=device,\n",
    "                                        vocab_size=len(ch2idx),\n",
    "                                        embed_dim=100,\n",
    "                                        filter_sizes=[8, 8, 8, 8],\n",
    "                                        num_filters=[100, 200, 200, 100],\n",
    "                                        num_classes=len(class2idx),\n",
    "                                        dropout=0.5,\n",
    "                                        learning_rate=0.25,\n",
    "                                        optimizerName=\"Adadelta\",\n",
    "                                        modelType=\"CNN\")\n",
    "                                        \n",
    "tn.train(device, cnn_rand, optimizer, train_dataloader, '01_4Layer_8KZ', writer, val_dataloader, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training...\n",
      "\n",
      " Epoch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
      "------------------------------------------------------------\n",
      "   1    |   1.549276   |  0.977869  |   72.90   |   60.29  \n",
      "   2    |   0.947057   |  0.786983  |   77.79   |   59.76  \n",
      "   3    |   0.780520   |  0.705370  |   80.21   |   59.74  \n",
      "   4    |   0.680181   |  0.670607  |   81.17   |   59.94  \n",
      "   5    |   0.608945   |  0.641855  |   82.01   |   60.62  \n",
      "   6    |   0.553080   |  0.625989  |   82.44   |   59.91  \n",
      "   7    |   0.509075   |  0.618870  |   82.91   |   59.96  \n",
      "   8    |   0.472580   |  0.612303  |   83.22   |   60.22  \n",
      "   9    |   0.444007   |  0.620402  |   83.55   |   59.92  \n",
      "  10    |   0.417853   |  0.607397  |   83.77   |   59.77  \n",
      "  11    |   0.394852   |  0.615766  |   83.75   |   60.17  \n",
      "  12    |   0.376072   |  0.616638  |   83.80   |   61.30  \n",
      "  13    |   0.359796   |  0.629411  |   84.02   |   61.98  \n",
      "  14    |   0.345248   |  0.626226  |   84.07   |   60.74  \n",
      "  15    |   0.333054   |  0.635083  |   84.20   |   60.24  \n",
      "  16    |   0.318974   |  0.641743  |   84.14   |   60.87  \n",
      "  17    |   0.311303   |  0.643197  |   84.15   |   60.43  \n",
      "  18    |   0.298746   |  0.649578  |   84.35   |   61.00  \n",
      "  19    |   0.290877   |  0.654797  |   84.28   |   59.29  \n",
      "  20    |   0.284529   |  0.662497  |   84.26   |   58.93  \n",
      "\n",
      "\n",
      "Training complete! Best accuracy: 84.35%.\n"
     ]
    }
   ],
   "source": [
    "# CNN-rand: Word vectors are randomly initialized.\n",
    "tn.set_seed(42)\n",
    "cnn_rand, optimizer = init.initilize_model(device=device,\n",
    "                                        vocab_size=len(ch2idx),\n",
    "                                        embed_dim=100,\n",
    "                                        filter_sizes=[16, 16, 16, 16],\n",
    "                                        num_filters=[100, 200, 200, 100],\n",
    "                                        num_classes=len(class2idx),\n",
    "                                        dropout=0.5,\n",
    "                                        learning_rate=0.25,\n",
    "                                        optimizerName=\"Adadelta\",\n",
    "                                        modelType=\"CNN\")\n",
    "                                        \n",
    "tn.train(device, cnn_rand, optimizer, train_dataloader, '02_4Layer_16KZ', writer, val_dataloader, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training...\n",
      "\n",
      " Epoch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
      "------------------------------------------------------------\n",
      "   1    |   1.630295   |  1.099746  |   68.81   |   88.06  \n",
      "   2    |   1.013283   |  0.862471  |   75.76   |   87.74  \n",
      "   3    |   0.781505   |  0.769756  |   78.16   |   87.90  \n",
      "   4    |   0.640039   |  0.732046  |   79.55   |   88.01  \n",
      "   5    |   0.537669   |  0.721706  |   79.99   |   88.16  \n",
      "   6    |   0.458645   |  0.714242  |   80.34   |   87.73  \n",
      "   7    |   0.402419   |  0.728888  |   80.70   |   87.96  \n",
      "   8    |   0.356646   |  0.730557  |   81.01   |   87.67  \n",
      "   9    |   0.319621   |  0.760302  |   81.20   |   87.64  \n",
      "  10    |   0.287817   |  0.765290  |   81.05   |   87.81  \n",
      "  11    |   0.266825   |  0.804605  |   80.67   |   87.80  \n",
      "  12    |   0.250435   |  0.797842  |   81.20   |   87.90  \n",
      "  13    |   0.231023   |  0.799861  |   81.23   |   87.53  \n",
      "  14    |   0.217110   |  0.825971  |   81.41   |   87.88  \n",
      "  15    |   0.207337   |  0.825835  |   81.30   |   87.58  \n",
      "  16    |   0.194720   |  0.835568  |   81.48   |   87.73  \n",
      "  17    |   0.184976   |  0.866361  |   81.53   |   87.59  \n",
      "  18    |   0.178384   |  0.884330  |   81.70   |   87.48  \n",
      "  19    |   0.173824   |  0.908309  |   81.73   |   87.66  \n",
      "  20    |   0.161290   |  0.920910  |   81.73   |   87.39  \n",
      "\n",
      "\n",
      "Training complete! Best accuracy: 81.73%.\n"
     ]
    }
   ],
   "source": [
    "# CNN-rand: Word vectors are randomly initialized.\n",
    "tn.set_seed(42)\n",
    "cnn_rand, optimizer = init.initilize_model(device=device,\n",
    "                                        vocab_size=len(ch2idx),\n",
    "                                        embed_dim=100,\n",
    "                                        filter_sizes=[32, 32, 32, 32],\n",
    "                                        num_filters=[100, 200, 200, 100],\n",
    "                                        num_classes=len(class2idx),\n",
    "                                        dropout=0.5,\n",
    "                                        learning_rate=0.25,\n",
    "                                        optimizerName=\"Adadelta\",\n",
    "                                        modelType=\"CNN\")\n",
    "                                        \n",
    "tn.train(device, cnn_rand, optimizer, train_dataloader, '03_4Layer_32KZ', writer, val_dataloader, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training...\n",
      "\n",
      " Epoch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
      "------------------------------------------------------------\n",
      "   1    |   1.765748   |  1.251953  |   64.18   |  146.07  \n",
      "   2    |   1.136959   |  1.026207  |   70.85   |  147.91  \n",
      "   3    |   0.821731   |  0.949986  |   73.05   |  149.56  \n",
      "   4    |   0.608853   |  0.934778  |   73.94   |  144.26  \n",
      "   5    |   0.463158   |  0.958263  |   74.42   |  144.32  \n",
      "   6    |   0.370929   |  0.980603  |   74.52   |  144.27  \n",
      "   7    |   0.301239   |  1.012578  |   74.89   |  140.04  \n",
      "   8    |   0.261558   |  1.055656  |   74.83   |  135.76  \n",
      "   9    |   0.224346   |  1.109466  |   74.99   |  132.54  \n",
      "  10    |   0.200673   |  1.106147  |   74.81   |  143.58  \n",
      "  11    |   0.177811   |  1.138093  |   74.87   |  145.48  \n",
      "  12    |   0.165410   |  1.175365  |   74.98   |  148.27  \n",
      "  13    |   0.150731   |  1.197865  |   75.09   |  145.55  \n",
      "  14    |   0.143135   |  1.229035  |   75.13   |  145.88  \n",
      "  15    |   0.132451   |  1.214772  |   75.02   |  149.78  \n",
      "  16    |   0.126437   |  1.280434  |   75.20   |  149.35  \n",
      "  17    |   0.118544   |  1.300523  |   75.29   |  149.10  \n",
      "  18    |   0.112248   |  1.309252  |   75.30   |  146.39  \n",
      "  19    |   0.105173   |  1.345666  |   75.47   |  151.98  \n",
      "  20    |   0.101516   |  1.344612  |   75.50   |  150.89  \n",
      "\n",
      "\n",
      "Training complete! Best accuracy: 75.50%.\n"
     ]
    }
   ],
   "source": [
    "# CNN-rand: Word vectors are randomly initialized.\n",
    "tn.set_seed(42)\n",
    "cnn_rand, optimizer = init.initilize_model(device=device,\n",
    "                                        vocab_size=len(ch2idx),\n",
    "                                        embed_dim=100,\n",
    "                                        filter_sizes=[64, 64, 64, 64],\n",
    "                                        num_filters=[100, 200, 200, 100],\n",
    "                                        num_classes=len(class2idx),\n",
    "                                        dropout=0.5,\n",
    "                                        learning_rate=0.25,\n",
    "                                        optimizerName=\"Adadelta\",\n",
    "                                        modelType=\"CNN\")\n",
    "                                        \n",
    "tn.train(device, cnn_rand, optimizer, train_dataloader, '04_4Layer_64KZ', writer, val_dataloader, epochs=20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "348b9cd948ce87438be2e622031b2ecfa29bc2d3ecc0fd03127b9a24b30227df"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
